# Cline's Project Intelligence for Diver Detection System

## Project Patterns

### Docker Environment Preferences
- Always use `--gpus all` and `--ipc=host` flags for Docker runs to ensure proper GPU access
- X11 forwarding requires proper configuration for visualization to work:
  - Set `DISPLAY` environment variable
  - Mount `/tmp/.X11-unix` directory
  - Mount `.Xauthority` file
  - Set `QT_X11_NO_MITSHM=1` to avoid shared memory issues

### YOLO-specific Patterns
- Use `yolo predict model=yolo11n.pt show=True` to test basic inference with visualization
- For non-GUI operation, use `show=False` to disable visualization
- Model files use `.pt` extension and are typically kept in the project root
- Models are gitignored (not stored in version control)
- Default source for inference is `/ultralytics/ultralytics/assets` with sample images
- Specify custom source with `source=path/to/image_or_folder`
- Default models detect 80 classes including person, can be used for initial diver testing

### Dataset Patterns
- VDD-C dataset is used for diver detection training
- Components needed for YOLO training:
  - images.zip (7.63 GB) - Main image files
  - yolo_labels.zip (27.82 MB) - Labels in YOLO format
- Use download_vddc.py script to download dataset:
  - `python download_vddc.py --readme` - Download just README
  - `python download_vddc.py --images --yolo-labels` - Download images and YOLO labels
  - `python download_vddc.py --all` - Download all dataset components
- Use prepare_vddc.py script to prepare dataset:
  - `python prepare_vddc.py` - Extract and organize with default settings
  - `python prepare_vddc.py --verify-only` - Just verify downloaded files
  - `python prepare_vddc.py --force` - Overwrite existing extracted files
  - `python prepare_vddc.py --train-val-split 0.8` - Custom train/val split ratio
- Dataset organization follows YOLO convention:
  - images/train/ - Contains training image files
  - images/val/ - Contains validation image files
  - labels/train/ - Contains corresponding training label files
  - labels/val/ - Contains corresponding validation label files
  - dataset.yaml - Configuration file for training

### Workflow Patterns
- Development happens on Ubuntu x86 with GPU
- Final deployment target is NVIDIA Jetson
- Use VS Code with devcontainers for consistent development environment
- SSH/Git operations require correct permissions (600) on key files

### File Organization
- Docker configuration in `Dockerfile` and `.devcontainer/`
- Model files in project root (`.pt` extension)
- Memory bank documentation in `memory-bank/`
- Dataset files in `sample_data/vdd-c/`
  - `raw/` - Raw downloaded files
  - `dataset/` - Processed YOLO-compatible dataset
  - `dataset/images/train/` - Training images
  - `dataset/images/val/` - Validation images
  - `dataset/labels/train/` - Training labels
  - `dataset/labels/val/` - Validation labels
  - `dataset/dataset.yaml` - YOLO dataset configuration
- Use relative paths in code to maintain portability

## Critical Implementation Paths

### GPU Access
- NVIDIA GPU must be properly accessible from the container
- Use `nvidia-smi` to verify GPU visibility
- CUDA initialization errors resolved with proper container configuration
- YOLOv8 works with CUDA when properly configured
- ultralytics/ultralytics:latest image includes PyTorch 2.6.0+cu126

### X11 Display
- Use `DISPLAY` environment variable to forward X11 display
- GTK dependencies are required for proper OpenCV GUI support
- Test with `yolo predict model=yolo11n.pt show=True` to verify visualization works
- Detection visualization runs at ~48ms per frame on test hardware

### SSH Configuration
- SSH files require specific permissions (directory: 700, key files: 600)
- When mounting from host, use separate directory with correct permissions
- Configure Git to use specific SSH command with proper key path

### Dataset Download and Management
- VDD-C dataset is large (7.63GB for images.zip)
- download_vddc.py script has resume capability for interrupted downloads
- Uses tqdm for progress tracking
- Downloads stored in sample_data/vdd-c/raw/ by default
- Format of VDD-C annotations is compatible with YOLO training

### Dataset Preparation
- prepare_vddc.py handles extraction and organization with proper structure
- Creates train/val split (default 80% training, 20% validation)
- Generates dataset.yaml file with appropriate paths and class definitions
- Uses temporary directories during extraction to avoid partial processing
- Verifies YOLO compatibility of prepared dataset
- Cleans up temporary files after processing

## Known Challenges

### OpenCV GTK Support
- Symptoms: "Environment does not support cv2.imshow()" or "Rebuild with GTK+"
- Solution: Install GTK development libraries in container
- Required packages: libgtk2.0-dev, libgtk-3-dev, and related dependencies
- Status: Resolved with proper dependency installation

### CUDA Initialization
- Symptoms: "CUDA unknown error" or initialization failure
- Solutions:
  - Use `--gpus all` flag for Docker
  - Set `NVIDIA_VISIBLE_DEVICES=all` environment variable
  - Ensure host drivers are compatible
- Status: Resolved with proper Docker configuration
- YOLOv8 uses CUDA for inference when available

### SSH Permission Issues
- Symptoms: "Bad owner or permissions" errors
- Solution: Create dedicated .ssh directory with proper permissions instead of mounting
- Status: Resolved with custom SSH directory approach

### Large Dataset Management
- Symptoms: Slow downloads, storage constraints
- Solution: 
  - Use download_vddc.py with resume capability
  - Download only necessary components (--images --yolo-labels)
  - Use prepare_vddc.py for efficient extraction and organization
  - Consider processing subsets for faster initial testing
- Status: Addressed with custom download and preparation scripts

## Project-Specific Intelligence

### VDD-C Dataset
- Contains 100,000+ annotated images of divers underwater
- Sourced from videos taken in pools and Caribbean
- Already annotated for diver detection
- Includes challenging underwater conditions (visibility, particles, lighting)
- Available formats:
  - YOLO labels (yolo_labels.zip) - Use this for our project
  - VOC labels (voc_labels.zip)
  - TFRecord labels (tfrecord_labels.zip)
  - TFSequence labels (multiple zip parts)
- Published by researchers at University of Minnesota
- Licensed under Creative Commons Attribution-ShareAlike 3.0

### Download Script Usage
- Command: `python download_vddc.py [options]`
- Important options:
  - `--images` - Download images.zip (7.63 GB)
  - `--yolo-labels` - Download YOLO format labels (27.82 MB)
  - `--readme` - Download README file (7.16 KB)
  - `--all` - Download all components
  - `--output-dir DIR` - Custom download location
- Features:
  - Resume capability for interrupted downloads
  - Progress tracking with tqdm
  - Download verification
  - Automatic retry on failure

### Preparation Script Usage
- Command: `python prepare_vddc.py [options]`
- Important options:
  - `--input-dir DIR` - Directory with downloaded files (default: sample_data/vdd-c/raw)
  - `--output-dir DIR` - Directory for prepared dataset (default: sample_data/vdd-c/dataset)
  - `--verify-only` - Only verify downloads without extraction
  - `--force` - Overwrite existing extracted files
  - `--train-val-split RATIO` - Custom train/validation split (default: 0.8)
  - `--skip-verification` - Skip final YOLO compatibility verification
- Features:
  - Download verification before extraction
  - Progress tracking during extraction
  - Random train/val splitting
  - dataset.yaml generation
  - YOLO compatibility verification
  - Temporary directory cleanup

### Model Selection
- YOLOv8n is a good starting point for testing (~6.3 MB size, 6.5 GFLOPs)
- Initial tests with YOLOv8n successful on sample images
- For Jetson deployment, models should be optimized for edge inference
- Consider nano or small variants for resource-constrained environments

### Performance Expectations
- Development GPU: YOLOv8n inference takes ~48ms per frame (~20 FPS) on test images
- Jetson target: 10-30 FPS depending on model size and optimization

### Underwater Conditions
- Underwater imagery presents special challenges:
  - Color distortion (blue/green dominant)
  - Light scattering effects
  - Particulates and bubbles
  - Variable visibility ranges
- VDD-C dataset already contains these challenging conditions
- Dataset augmentation may still be beneficial for specific conditions

### Testing Results
- Default YOLOv8n model successfully detects persons in sample images
- Detection time: ~48ms inference (not including pre/post-processing)
- Next steps: test on actual underwater diver images from VDD-C dataset 