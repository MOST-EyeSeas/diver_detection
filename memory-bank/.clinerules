# Cline's Project Intelligence for Diver Detection System

## Project Patterns

### Docker Environment Preferences
- Always use `--gpus all` and `--ipc=host` flags for Docker runs to ensure proper GPU access
- X11 forwarding requires proper configuration for visualization to work:
  - Set `DISPLAY` environment variable
  - Mount `/tmp/.X11-unix` directory
  - Mount `.Xauthority` file
  - Set `QT_X11_NO_MITSHM=1` to avoid shared memory issues

### YOLO-specific Patterns
- Use `yolo predict model=<model_name>.pt show=True` to test basic inference with visualization (e.g., `yolov11n.pt`, `yolov12n.pt`). Note: Newer models may require manual download first (see below).
- For non-GUI operation, use `show=False` to disable visualization
- Model files use `.pt` extension and are typically kept in the project root
- Models are gitignored (not stored in version control)
- Default source for inference is `/ultralytics/ultralytics/assets` with sample images
- Specify custom source with `source=path/to/image_or_folder`
- Default models detect 80 classes including person, can be used for initial diver testing
- For training, use `yolo train model=<model_name>.pt data=path/to/dataset.yaml epochs=<num> imgsz=<size>`
- **YOLO provides comprehensive automatic logging:**
  - `results.csv` - All training metrics per epoch (mAP, precision, recall, losses)
  - `best.pt` and `last.pt` - Model weights (best validation performance and final epoch)
  - Training visualizations (confusion matrix, PR curves, batch images)
  - TensorBoard logs for detailed analysis
  - No manual log saving required - everything is automatic

### Dataset Patterns
- VDD-C dataset is used for diver detection training
- Components needed for YOLO training:
  - images.zip (8.38 GB) - Main image files
  - yolo_labels.zip (6.06 MB) - Labels in YOLO format
- Use download_vddc.py script to download dataset:
  - `python download_vddc.py --readme` - Download just README
  - `python download_vddc.py --images --yolo-labels` - Download images and YOLO labels
  - `python download_vddc.py --all` - Download all components
- Use prepare_vddc.py script to prepare dataset:
  - `python prepare_vddc.py` - Extract and organize with default settings
  - `python prepare_vddc.py --verify-only` - Just verify downloaded files
  - `python prepare_vddc.py --force` - Overwrite existing extracted files
  - `python prepare_vddc.py --train-val-split 0.8` - Custom train/val split ratio
- Dataset organization follows YOLO convention:
  - images/train/ - Contains training image files
  - images/val/ - Contains validation image files
  - labels/train/ - Contains corresponding training label files
  - labels/val/ - Contains corresponding validation label files
  - dataset.yaml - Configuration file for training
- Label formats:
  - YOLO format: class_id x_center y_center width height (normalized 0-1)
  - Single class (0 = diver) in our dataset
  - Example: `0 0.266927 0.067130 0.186979 0.134259`

### **Dataset Enhancement Patterns (aneris_enhance)**
- **Enhancement pipeline using aneris_enhance for underwater image processing:**
  - Red channel correction (multiply by 1.2) to compensate for underwater color loss
  - Contrast stretching using CLAHE (Contrast Limited Adaptive Histogram Equalization)
  - Processes images while maintaining YOLO label compatibility (bounding boxes unchanged)
- **Batch enhancement using enhance_dataset.py:**
  - `python enhance_dataset.py` - Enhance entire dataset (training + validation)
  - `python enhance_dataset.py --test-only` - Process small subset (20 images) for testing
  - `python enhance_dataset.py --skip-validation` - Process only training images
  - `python enhance_dataset.py --workers N` - Configure parallel processing (default: 4)
  - `python enhance_dataset.py --force` - Overwrite existing enhanced dataset
  - `python enhance_dataset.py --no-progress` - Disable tqdm progress bars
- **Enhancement performance characteristics:**
  - Achieves 8.2 FPS processing speed (significantly faster than documented 3.7 FPS)
  - 100% success rate across 11,752 images in testing
  - Parallel processing with 4 workers maximizes efficiency
  - Statistical improvements: brightness (116.5→147.0), improved contrast
  - Total processing time: ~23 minutes for full VDD-C dataset
- **Enhanced dataset structure:**
  - `sample_data/vdd-c/dataset_enhanced/` - Enhanced images with same YOLO structure
  - `dataset_enhanced.yaml` - Configuration file pointing to enhanced dataset
  - Labels copied unchanged from original dataset (preprocessing doesn't affect annotations)

### **4-Way Training Comparison Patterns**
- **Comparison matrix approach:**
  1. YOLOv11n + Original Dataset (`runs/comparison/v11n_original/`)
  2. YOLOv11n + Enhanced Dataset (`runs/comparison/v11n_enhanced/`)
  3. YOLOv12n + Original Dataset (`runs/comparison/v12n_original/`)
  4. YOLOv12n + Enhanced Dataset (`runs/comparison/v12n_enhanced/`)
- **Standardized training commands:**
  ```bash
  # Original dataset training
  yolo train model=yolo11n.pt data=sample_data/vdd-c/dataset/dataset.yaml epochs=50 imgsz=640 batch=16 device=0 project=runs/comparison name=v11n_original
  yolo train model=yolo12n.pt data=sample_data/vdd-c/dataset/dataset.yaml epochs=50 imgsz=640 batch=16 device=0 project=runs/comparison name=v12n_original
  
  # Enhanced dataset training
  yolo train model=yolo11n.pt data=sample_data/vdd-c/dataset_enhanced/dataset_enhanced.yaml epochs=50 imgsz=640 batch=16 device=0 project=runs/comparison name=v11n_enhanced
  yolo train model=yolo12n.pt data=sample_data/vdd-c/dataset_enhanced/dataset_enhanced.yaml epochs=50 imgsz=640 batch=16 device=0 project=runs/comparison name=v12n_enhanced
  ```
- **Results analysis using compare_results.py:**
  - `python compare_results.py` - Generate comparison table of all experiments
  - `python compare_results.py --save-plots` - Include training curve visualizations
  - Automatically identifies best performing model/dataset combination
  - Analyzes enhancement impact (original vs enhanced) for each model
  - Exports detailed results to `training_comparison.csv`
  - Provides deployment recommendations (Jetson considerations, TensorRT optimization)

### Workflow Patterns
- Development happens on Ubuntu x86 with GPU
- Final deployment target is NVIDIA Jetson
- Use VS Code with devcontainers for consistent development environment
- SSH/Git operations require correct permissions (600) on key files
- **Memory Bank maintenance is critical:** Update activeContext.md, progress.md, and .clinerules after major milestones

### File Organization
- Docker configuration in `Dockerfile` and `.devcontainer/`
- Model files in project root (`.pt` extension)
- Memory bank documentation in `memory-bank/`
- **Dataset files in `sample_data/vdd-c/`:**
  - `raw/` - Raw downloaded files
  - `dataset/` - Original processed YOLO-compatible dataset
  - `dataset_enhanced/` - Enhanced dataset with aneris_enhance preprocessing
  - `dataset/images/train/` - Original training images
  - `dataset/images/val/` - Original validation images
  - `dataset_enhanced/images/train/` - Enhanced training images
  - `dataset_enhanced/images/val/` - Enhanced validation images
  - `dataset/labels/train/` and `dataset_enhanced/labels/train/` - Training labels (identical)
  - `dataset/labels/val/` and `dataset_enhanced/labels/val/` - Validation labels (identical)
  - `dataset/dataset.yaml` and `dataset_enhanced/dataset_enhanced.yaml` - Configuration files
- **Training results in `runs/comparison/`:**
  - `v11n_original/`, `v11n_enhanced/`, `v12n_original/`, `v12n_enhanced/` - Training outputs
  - Each contains: `results.csv`, `weights/best.pt`, `weights/last.pt`, visualizations
- **Analysis scripts in project root:**
  - `enhance_dataset.py` - Batch image enhancement
  - `compare_results.py` - Training results comparison and analysis
- Use relative paths in code to maintain portability

## Critical Implementation Paths

### GPU Access
- NVIDIA GPU must be properly accessible from the container
- Use `nvidia-smi` to verify GPU visibility
- CUDA initialization errors resolved with proper container configuration
- YOLOv8 works with CUDA when properly configured
- ultralytics/ultralytics:latest image includes PyTorch 2.6.0+cu126

### X11 Display
- Use `DISPLAY` environment variable to forward X11 display
- GTK dependencies are required for proper OpenCV GUI support
- Test with `yolo predict model=yolo11n.pt show=True` to verify visualization works
- Detection visualization runs at ~48ms per frame on test hardware

### SSH Configuration
- SSH files require specific permissions (directory: 700, key files: 600)
- When mounting from host, use separate directory with correct permissions
- Configure Git to use specific SSH command with proper key path

### Dataset Download and Management
- VDD-C dataset is large (8.38GB for images.zip)
- download_vddc.py script has resume capability for interrupted downloads
- Uses tqdm for progress tracking
- Downloads stored in sample_data/vdd-c/raw/ by default
- Format of VDD-C annotations is compatible with YOLO training

### Dataset Preparation
- prepare_vddc.py handles extraction and organization with proper structure
- Creates train/val split (default 80% training, 20% validation)
- Generates dataset.yaml file with appropriate paths and class definitions
- Uses temporary directories during extraction to avoid partial processing
- Verifies YOLO compatibility of prepared dataset
- Cleans up temporary files after processing
- Processed dataset statistics:
  - Original: 105,552 total images (84,441 training, 21,111 validation)
  - Matched labels: 83,858 training, 20,972 validation
  - Final processed: 5,996 training, 5,756 validation images

### **Dataset Enhancement Pipeline**
- **aneris_enhance integration via subprocess for reliability:**
  ```bash
  python3 aneris_enhance/python/src/underwater_enhance.py input_image.jpg output_image.jpg
  ```
- **Batch processing with enhance_dataset.py:**
  - Uses multiprocessing.Pool for parallel image processing
  - tqdm progress bars for real-time monitoring
  - Robust error handling with detailed error reporting
  - Automatic directory structure creation and label copying
  - Fallback enhancement methods if aneris_enhance unavailable
- **Performance optimization:**
  - 4 parallel workers achieve 8.2 FPS processing speed
  - Subprocess calls more reliable than direct imports for aneris_enhance
  - Progress tracking essential for large datasets (11,752 images)
  - Memory efficient processing (images processed in batches)

### YOLO Training
- Use the dataset.yaml file from prepared dataset (`sample_data/vdd-c/dataset/dataset.yaml`).
- Configure appropriate batch size based on available GPU memory (started with 16).
- Set training epochs (started comparison with 50).
- Use pretrained weights for faster convergence (e.g., `yolov11n.pt`, `yolov12n.pt`).
- Monitor training with built-in tensorboard logging (`runs/train_*/diver_detection/`).
- **Integrate with WandB for enhanced tracking:**
  - Install WandB: `pip install wandb`
  - Login: `wandb login` (requires API key)
  - Enable in YOLO: `yolo settings wandb=True`
  - Training command automatically logs to WandB using `project` and `name` arguments.
- **4-way comparison training commands (standardized):**
  ```bash
  # YOLOv11n Original
  yolo train model=yolo11n.pt data=sample_data/vdd-c/dataset/dataset.yaml epochs=50 imgsz=640 batch=16 device=0 project=runs/comparison name=v11n_original
  
  # YOLOv11n Enhanced
  yolo train model=yolo11n.pt data=sample_data/vdd-c/dataset_enhanced/dataset_enhanced.yaml epochs=50 imgsz=640 batch=16 device=0 project=runs/comparison name=v11n_enhanced
  
  # YOLOv12n Original
  yolo train model=yolo12n.pt data=sample_data/vdd-c/dataset/dataset.yaml epochs=50 imgsz=640 batch=16 device=0 project=runs/comparison name=v12n_original
  
  # YOLOv12n Enhanced
  yolo train model=yolo12n.pt data=sample_data/vdd-c/dataset_enhanced/dataset_enhanced.yaml epochs=50 imgsz=640 batch=16 device=0 project=runs/comparison name=v12n_enhanced
  ```
- **Expected metrics to track:**
  - mAP50 (primary metric for object detection)
  - mAP50-95 (stricter metric across IoU thresholds)
  - Precision and Recall
  - Training and validation losses
  - Training speed (epochs/hour)

### **Training Results Analysis**
- **YOLO provides automatic comprehensive logging:**
  - `results.csv` - Complete training metrics per epoch
  - `weights/best.pt` - Best model based on validation mAP
  - `weights/last.pt` - Final epoch model
  - Visualizations: confusion matrix, PR curves, training curves
  - TensorBoard logs for detailed analysis
- **compare_results.py provides automated analysis:**
  - Loads results from all 4 training experiments automatically
  - Generates comparison tables with key metrics
  - Creates training curve visualizations
  - Analyzes enhancement impact (original vs enhanced for each model)
  - Recommends best model for deployment
  - Exports detailed CSV for further analysis
- **Key analysis patterns:**
  - mAP50 is primary metric for model selection
  - Enhancement impact measured as delta between original/enhanced for same model
  - Jetson deployment considerations favor accuracy/speed balance
  - Best model recommendation includes deployment notes

## Known Challenges

### OpenCV GTK Support
- Symptoms: "Environment does not support cv2.imshow()" or "Rebuild with GTK+"
- Solution: Install GTK development libraries in container
- Required packages: libgtk2.0-dev, libgtk-3-dev, and related dependencies
- Status: Resolved with proper dependency installation

### CUDA Initialization
- Symptoms: "CUDA unknown error" or initialization failure
- Solutions:
  - Use `--gpus all` flag for Docker
  - Set `NVIDIA_VISIBLE_DEVICES=all` environment variable
  - Ensure host drivers are compatible
- Status: Resolved with proper Docker configuration
- YOLOv8 uses CUDA for inference when available

### SSH Permission Issues
- Symptoms: "Bad owner or permissions" errors
- Solution: Create dedicated .ssh directory with proper permissions instead of mounting
- Status: Resolved with custom SSH directory approach

### Large Dataset Management
- Symptoms: Slow downloads, storage constraints
- Solution: 
  - Use download_vddc.py with resume capability
  - Download only necessary components (--images --yolo-labels)
  - Use prepare_vddc.py for efficient extraction and organization
  - Consider processing subsets for faster initial testing
- Status: Resolved with custom download and preparation scripts

### Label File Matching
- Symptoms: Labels not being found for images
- Solution:
  - VDD-C label files use a specific naming convention: [directory]_[image_name].txt
  - Modified prepare_vddc.py to check multiple possible label locations
  - Added support for checking in yolo/train, yolo/val, and yolo/test directories
- Status: Resolved with improved label matching logic

### Manual Model Weight Download (YOLOv11/v12)
- Symptom: `FileNotFoundError` for `.pt` file during `yolo train` or `yolo predict` even with latest `ultralytics` package.
- Solution: Manually download weights using `wget` before training.
- Example commands:
  ```bash
  wget https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt
  wget https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo12n.pt
  # May need to rename if *.pt.1 is created
  mv yolo11n.pt.1 yolo11n.pt
  mv yolo12n.pt.1 yolo12n.pt
  ```
- Status: Workaround implemented and successful.

### **Large-Scale Image Enhancement Processing**
- Symptoms: Processing 11,752 images could be slow or memory-intensive
- Solution:
  - Use multiprocessing with 4 workers for parallel processing
  - Process images via subprocess calls to aneris_enhance (more reliable than imports)
  - Implement comprehensive progress tracking with tqdm
  - Use efficient file I/O patterns and cleanup temporary files
- Performance achieved: 8.2 FPS (significantly faster than expected 3.7 FPS)
- Status: Resolved with enhance_dataset.py parallel processing architecture

### **Training Time and Resource Management**
- Challenge: 4 training runs × 50 epochs = potentially 8-16 hours total
- Solution:
  - YOLO automatic checkpointing allows resumable training
  - Can analyze results incrementally as training runs complete
  - WandB integration provides cloud monitoring and comparison
  - Results analysis tools prepared in advance
- Status: Mitigated through automated infrastructure and resumable training

## Project-Specific Intelligence

### VDD-C Dataset
- Contains 100,000+ annotated images of divers underwater
- Sourced from videos taken in pools and Caribbean
- Already annotated for diver detection
- Includes challenging underwater conditions (visibility, particles, lighting)
- Available formats:
  - YOLO labels (yolo_labels.zip) - Used for this project
  - VOC labels (voc_labels.zip)
  - TFRecord labels (tfrecord_labels.zip)
  - TFSequence labels (multiple zip parts)
- Published by researchers at University of Minnesota
- Licensed under Creative Commons Attribution-ShareAlike 3.0
- Label file organization:
  - Stored in yolo/train, yolo/val, yolo/test directories
  - Named as [directory]_[image_name].txt (e.g., barbados_scuba_001_A_0101.txt)

### Download Script Usage
- Command: `python download_vddc.py [options]`
- Important options:
  - `--images` - Download images.zip (8.38 GB)
  - `--yolo-labels` - Download YOLO format labels (6.06 MB)
  - `--readme` - Download README file (7.16 KB)
  - `--all` - Download all components
  - `--output-dir DIR` - Custom download location
  - `--no-progress` - Disable progress bar (if tqdm is unavailable)
- Features:
  - Resume capability for interrupted downloads
  - Progress tracking with tqdm (optional)
  - Download verification
  - Automatic retry on failure

### Preparation Script Usage
- Command: `python prepare_vddc.py [options]`
- Important options:
  - `--input-dir DIR` - Directory with downloaded files (default: sample_data/vdd-c/raw)
  - `--output-dir DIR` - Directory for prepared dataset (default: sample_data/vdd-c/dataset)
  - `--verify-only` - Only verify downloads without extraction
  - `--force` - Overwrite existing extracted files
  - `--train-val-split RATIO` - Custom train/validation split (default: 0.8)
  - `--skip-verification` - Skip final YOLO compatibility verification
  - `--no-progress` - Disable progress bar (if tqdm is unavailable)
- Features:
  - Download verification before extraction
  - Progress tracking during extraction (optional)
  - Random train/val splitting
  - dataset.yaml generation
  - YOLO compatibility verification
  - Temporary directory cleanup
- Output:
  - Creates YOLO-compatible dataset structure
  - Generates dataset.yaml file
  - Final dataset statistics:
    - 5,996 training images with labels
    - 5,756 validation images with labels

### **Enhancement Script Usage**
- Command: `python enhance_dataset.py [options]`
- Important options:
  - `--input-dataset DIR` - Source dataset directory (default: sample_data/vdd-c/dataset)
  - `--output-dataset DIR` - Enhanced dataset directory (default: sample_data/vdd-c/dataset_enhanced)
  - `--workers N` - Number of parallel workers (default: 4)
  - `--test-only` - Process only 20 images for testing
  - `--force` - Overwrite existing enhanced dataset
  - `--skip-validation` - Process only training images
  - `--no-progress` - Disable tqdm progress bars
- Features:
  - Parallel processing with configurable workers
  - aneris_enhance integration via subprocess
  - Automatic label copying and dataset.yaml generation
  - Comprehensive error handling and reporting
  - tqdm progress bars for real-time monitoring
- Performance:
  - 8.2 FPS processing speed (11,752 images in ~23 minutes)
  - 100% success rate in testing
  - Statistical improvements: brightness increase, better contrast

### **Results Comparison Script Usage**
- Command: `python compare_results.py [options]`
- Important options:
  - `--results-dir DIR` - Directory containing training results (default: runs/comparison)
  - `--save-plots` - Generate and save training curve visualizations
- Features:
  - Automatic loading of results from all 4 training experiments
  - Performance metrics comparison table generation
  - Enhancement impact analysis (original vs enhanced datasets)
  - Model architecture comparison (YOLOv11n vs YOLOv12n)
  - Training curve plotting and visualization
  - Best model recommendation with deployment considerations
  - CSV export for detailed analysis
- Output:
  - Console summary table with key metrics
  - `training_comparison.csv` - Detailed results export
  - `training_comparison.png` - Training curves visualization (if --save-plots)
  - Enhancement impact analysis with delta calculations
  - Deployment recommendations (Jetson considerations, TensorRT notes)

### Dataset Setup Script
- Command: `./setup_dataset.sh`
- Purpose: Runs both download and preparation scripts sequentially.
- Usage: Convenient way to download and prepare the dataset in environments without tqdm.
- Executes:
  - `python3 download_vddc.py --images --yolo-labels --no-progress`
  - `python3 prepare_vddc.py --no-progress`

### **YOLO Training Commands (4-Way Comparison)**
- **Standardized training parameters:** 50 epochs, batch size 16, image size 640, device 0
- **Project structure:** All results saved to `runs/comparison/` with descriptive names
- **Training commands:**
  ```bash
  # YOLOv11n Original Dataset
  yolo train model=yolo11n.pt data=sample_data/vdd-c/dataset/dataset.yaml epochs=50 imgsz=640 batch=16 device=0 project=runs/comparison name=v11n_original
  
  # YOLOv11n Enhanced Dataset
  yolo train model=yolo11n.pt data=sample_data/vdd-c/dataset_enhanced/dataset_enhanced.yaml epochs=50 imgsz=640 batch=16 device=0 project=runs/comparison name=v11n_enhanced
  
  # YOLOv12n Original Dataset
  yolo train model=yolo12n.pt data=sample_data/vdd-c/dataset/dataset.yaml epochs=50 imgsz=640 batch=16 device=0 project=runs/comparison name=v12n_original
  
  # YOLOv12n Enhanced Dataset
  yolo train model=yolo12n.pt data=sample_data/vdd-c/dataset_enhanced/dataset_enhanced.yaml epochs=50 imgsz=640 batch=16 device=0 project=runs/comparison name=v12n_enhanced
  ```

### Model Selection & Performance
- **Current 4-way comparison:** YOLOv11n/v12n × Original/Enhanced datasets
- YOLOv11n: ~5.4MB (downloaded size), promising early results (mAP50=0.693 after 1 epoch)
- YOLOv12n: ~5.3MB (downloaded size), attention-centric architecture
- For Jetson deployment, nano variants (`n`) chosen for resource constraints
- **Performance expectations:**
  - Development GPU: ~20 FPS inference
  - Jetson target: 10-30 FPS depending on optimization
  - Enhancement preprocessing: 8.2 FPS batch processing

### **Underwater Conditions & Enhancement**
- **Underwater imaging challenges:**
  - Color distortion (blue/green dominant, red channel loss)
  - Light scattering and attenuation effects
  - Particulates, bubbles, and suspended matter
  - Variable visibility ranges and lighting conditions
- **aneris_enhance addresses these challenges:**
  - Red channel correction (multiply by 1.2) compensates for underwater color loss
  - CLAHE contrast stretching improves visibility in low-contrast conditions
  - Statistical improvements validated: brightness (116.5→147.0), better contrast
- **VDD-C dataset characteristics:**
  - Already contains challenging underwater conditions (natural data augmentation)
  - Pool and Caribbean environments provide diverse lighting/visibility scenarios
  - Enhancement preprocessing may provide additional performance gains

### **Testing and Validation Results**
- Default YOLO models successfully detect persons in sample images
- Initial YOLOv11n training shows promising results (mAP50=0.693 after 1 epoch)
- Enhancement pipeline achieves 100% success rate across 11,752 images
- Processing performance exceeds expectations (8.2 FPS vs documented 3.7 FPS)
- **Early indicators suggest strong final performance across all model variants** 