# Cline's Project Intelligence for Diver Detection System

## Project Patterns

### Docker Environment Preferences
- Always use `--gpus all` and `--ipc=host` flags for Docker runs to ensure proper GPU access
- X11 forwarding requires proper configuration for visualization to work:
  - Set `DISPLAY` environment variable
  - Mount `/tmp/.X11-unix` directory
  - Mount `.Xauthority` file
  - Set `QT_X11_NO_MITSHM=1` to avoid shared memory issues

### YOLO-specific Patterns
- Use `yolo predict model=yolo11n.pt show=True` to test basic inference with visualization
- For non-GUI operation, use `show=False` to disable visualization
- Model files use `.pt` extension and are typically kept in the project root
- Models are gitignored (not stored in version control)
- Default source for inference is `/ultralytics/ultralytics/assets` with sample images
- Specify custom source with `source=path/to/image_or_folder`
- Default models detect 80 classes including person, can be used for initial diver testing
- For training, use `yolo train model=yolov8n.pt data=path/to/dataset.yaml epochs=100 imgsz=640`

### Dataset Patterns
- VDD-C dataset is used for diver detection training
- Components needed for YOLO training:
  - images.zip (8.38 GB) - Main image files
  - yolo_labels.zip (6.06 MB) - Labels in YOLO format
- Use download_vddc.py script to download dataset:
  - `python download_vddc.py --readme` - Download just README
  - `python download_vddc.py --images --yolo-labels` - Download images and YOLO labels
  - `python download_vddc.py --all` - Download all components
- Use prepare_vddc.py script to prepare dataset:
  - `python prepare_vddc.py` - Extract and organize with default settings
  - `python prepare_vddc.py --verify-only` - Just verify downloaded files
  - `python prepare_vddc.py --force` - Overwrite existing extracted files
  - `python prepare_vddc.py --train-val-split 0.8` - Custom train/val split ratio
- Dataset organization follows YOLO convention:
  - images/train/ - Contains training image files
  - images/val/ - Contains validation image files
  - labels/train/ - Contains corresponding training label files
  - labels/val/ - Contains corresponding validation label files
  - dataset.yaml - Configuration file for training
- Label formats:
  - YOLO format: class_id x_center y_center width height (normalized 0-1)
  - Single class (0 = diver) in our dataset
  - Example: `0 0.266927 0.067130 0.186979 0.134259`

### Workflow Patterns
- Development happens on Ubuntu x86 with GPU
- Final deployment target is NVIDIA Jetson
- Use VS Code with devcontainers for consistent development environment
- SSH/Git operations require correct permissions (600) on key files

### File Organization
- Docker configuration in `Dockerfile` and `.devcontainer/`
- Model files in project root (`.pt` extension)
- Memory bank documentation in `memory-bank/`
- Dataset files in `sample_data/vdd-c/`
  - `raw/` - Raw downloaded files
  - `dataset/` - Processed YOLO-compatible dataset
  - `dataset/images/train/` - Training images
  - `dataset/images/val/` - Validation images
  - `dataset/labels/train/` - Training labels
  - `dataset/labels/val/` - Validation labels
  - `dataset/dataset.yaml` - YOLO dataset configuration
- Use relative paths in code to maintain portability

## Critical Implementation Paths

### GPU Access
- NVIDIA GPU must be properly accessible from the container
- Use `nvidia-smi` to verify GPU visibility
- CUDA initialization errors resolved with proper container configuration
- YOLOv8 works with CUDA when properly configured
- ultralytics/ultralytics:latest image includes PyTorch 2.6.0+cu126

### X11 Display
- Use `DISPLAY` environment variable to forward X11 display
- GTK dependencies are required for proper OpenCV GUI support
- Test with `yolo predict model=yolo11n.pt show=True` to verify visualization works
- Detection visualization runs at ~48ms per frame on test hardware

### SSH Configuration
- SSH files require specific permissions (directory: 700, key files: 600)
- When mounting from host, use separate directory with correct permissions
- Configure Git to use specific SSH command with proper key path

### Dataset Download and Management
- VDD-C dataset is large (8.38GB for images.zip)
- download_vddc.py script has resume capability for interrupted downloads
- Uses tqdm for progress tracking
- Downloads stored in sample_data/vdd-c/raw/ by default
- Format of VDD-C annotations is compatible with YOLO training

### Dataset Preparation
- prepare_vddc.py handles extraction and organization with proper structure
- Creates train/val split (default 80% training, 20% validation)
- Generates dataset.yaml file with appropriate paths and class definitions
- Uses temporary directories during extraction to avoid partial processing
- Verifies YOLO compatibility of prepared dataset
- Cleans up temporary files after processing
- Processed dataset statistics:
  - Original: 105,552 total images (84,441 training, 21,111 validation)
  - Matched labels: 83,858 training, 20,972 validation
  - Final processed: 5,997 training, 5,763 validation images

### YOLO Training
- Use the dataset.yaml file from prepared dataset
- Configure appropriate batch size based on available GPU memory
- Set training epochs (typically 50-100 for initial training)
- Use pretrained weights for faster convergence (yolov8n.pt)
- Monitor training with built-in tensorboard logging
- Expected metrics to track:
  - mAP (mean Average Precision)
  - Precision and recall
  - Loss values (box loss, class loss, etc.)

## Known Challenges

### OpenCV GTK Support
- Symptoms: "Environment does not support cv2.imshow()" or "Rebuild with GTK+"
- Solution: Install GTK development libraries in container
- Required packages: libgtk2.0-dev, libgtk-3-dev, and related dependencies
- Status: Resolved with proper dependency installation

### CUDA Initialization
- Symptoms: "CUDA unknown error" or initialization failure
- Solutions:
  - Use `--gpus all` flag for Docker
  - Set `NVIDIA_VISIBLE_DEVICES=all` environment variable
  - Ensure host drivers are compatible
- Status: Resolved with proper Docker configuration
- YOLOv8 uses CUDA for inference when available

### SSH Permission Issues
- Symptoms: "Bad owner or permissions" errors
- Solution: Create dedicated .ssh directory with proper permissions instead of mounting
- Status: Resolved with custom SSH directory approach

### Large Dataset Management
- Symptoms: Slow downloads, storage constraints
- Solution: 
  - Use download_vddc.py with resume capability
  - Download only necessary components (--images --yolo-labels)
  - Use prepare_vddc.py for efficient extraction and organization
  - Consider processing subsets for faster initial testing
- Status: Resolved with custom download and preparation scripts

### Label File Matching
- Symptoms: Labels not being found for images
- Solution:
  - VDD-C label files use a specific naming convention: [directory]_[image_name].txt
  - Modified prepare_vddc.py to check multiple possible label locations
  - Added support for checking in yolo/train, yolo/val, and yolo/test directories
- Status: Resolved with improved label matching logic

## Project-Specific Intelligence

### VDD-C Dataset
- Contains 100,000+ annotated images of divers underwater
- Sourced from videos taken in pools and Caribbean
- Already annotated for diver detection
- Includes challenging underwater conditions (visibility, particles, lighting)
- Available formats:
  - YOLO labels (yolo_labels.zip) - Used for this project
  - VOC labels (voc_labels.zip)
  - TFRecord labels (tfrecord_labels.zip)
  - TFSequence labels (multiple zip parts)
- Published by researchers at University of Minnesota
- Licensed under Creative Commons Attribution-ShareAlike 3.0
- Label file organization:
  - Stored in yolo/train, yolo/val, yolo/test directories
  - Named as [directory]_[image_name].txt (e.g., barbados_scuba_001_A_0101.txt)

### Download Script Usage
- Command: `python download_vddc.py [options]`
- Important options:
  - `--images` - Download images.zip (8.38 GB)
  - `--yolo-labels` - Download YOLO format labels (6.06 MB)
  - `--readme` - Download README file (7.16 KB)
  - `--all` - Download all components
  - `--output-dir DIR` - Custom download location
- Features:
  - Resume capability for interrupted downloads
  - Progress tracking with tqdm
  - Download verification
  - Automatic retry on failure

### Preparation Script Usage
- Command: `python prepare_vddc.py [options]`
- Important options:
  - `--input-dir DIR` - Directory with downloaded files (default: sample_data/vdd-c/raw)
  - `--output-dir DIR` - Directory for prepared dataset (default: sample_data/vdd-c/dataset)
  - `--verify-only` - Only verify downloads without extraction
  - `--force` - Overwrite existing extracted files
  - `--train-val-split RATIO` - Custom train/validation split (default: 0.8)
  - `--skip-verification` - Skip final YOLO compatibility verification
- Features:
  - Download verification before extraction
  - Progress tracking during extraction
  - Random train/val splitting
  - dataset.yaml generation
  - YOLO compatibility verification
  - Temporary directory cleanup
- Output:
  - Creates YOLO-compatible dataset structure
  - Generates dataset.yaml file
  - Final dataset statistics:
    - 5,997 training images with labels
    - 5,763 validation images with labels

### YOLO Training Command
- Basic training command:
  ```
  yolo train model=yolov8n.pt data=sample_data/vdd-c/dataset/dataset.yaml epochs=100 imgsz=640
  ```
- Important parameters:
  - `model`: Starting model (pretrained)
  - `data`: Path to dataset.yaml
  - `epochs`: Number of training epochs
  - `imgsz`: Input image size
  - `batch`: Batch size
  - `patience`: Early stopping patience
  - `device`: GPU device selection

### Model Selection
- YOLOv8n is a good starting point for testing (~6.3 MB size, 6.5 GFLOPs)
- Initial tests with YOLOv8n successful on sample images
- For Jetson deployment, models should be optimized for edge inference
- Consider nano or small variants for resource-constrained environments

### Performance Expectations
- Development GPU: YOLOv8n inference takes ~48ms per frame (~20 FPS) on test images
- Jetson target: 10-30 FPS depending on model size and optimization

### Underwater Conditions
- Underwater imagery presents special challenges:
  - Color distortion (blue/green dominant)
  - Light scattering effects
  - Particulates and bubbles
  - Variable visibility ranges
- VDD-C dataset already contains these challenging conditions
- Dataset augmentation may still be beneficial for specific conditions

### Testing Results
- Default YOLOv8n model successfully detects persons in sample images
- Detection time: ~48ms inference (not including pre/post-processing)
- Next steps: train custom model on prepared VDD-C dataset 